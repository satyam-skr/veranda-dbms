import OpenAI from 'openai';
import dotenv from 'dotenv';

dotenv.config({ path: '.env.local' });

async function testOpenRouter() {
  const apiKey = process.env.OPENAI_API_KEY;
  const baseURL = process.env.OPENAI_BASE_URL;
  const model = process.env.OPENAI_MODEL;

  console.log('üîç Testing OpenRouter Configuration...');
  console.log(`üì° URL: ${baseURL}`);
  console.log(`ü§ñ Model: ${model}`);
  console.log(`üîë Key: ${apiKey?.substring(0, 10)}...`);

  if (!apiKey) {
    console.error('‚ùå Missing OPENAI_API_KEY');
    process.exit(1);
  }

  const client = new OpenAI({
    apiKey,
    baseURL,
    defaultHeaders: {
      'HTTP-Referer': 'https://autofix.dev',
      'X-Title': 'AutoFix Platform Test',
    }
  });

  const models = [
    model || 'openai/gpt-oss-120b:free',
    'mistralai/mistral-7b-instruct:free',
    'google/gemma-7b-it:free',
    'google/learnlm-1.5-pro-experimental:free'
  ];

  for (const m of models) {
    console.log(`\nüß™ Testing model: ${m}...`);
    try {
      const response = await client.chat.completions.create({
        model: m,
        messages: [{ role: 'user', content: 'Say "OK"' }],
        max_tokens: 10,
      });

      console.log(`‚úÖ Success with ${m}!`);
      console.log('üì• Response:', response.choices[0]?.message?.content);
      
      // Update .env.local if the user's model failed but another worked
      if (m !== models[0]) {
        console.log(`üí° Suggestion: Update OPENAI_MODEL to ${m} in .env.local`);
      }
      
      process.exit(0);
    } catch (error: any) {
      console.error(`‚ùå Failed with ${m}`);
      console.error('Error:', error.message);
    }
  }

  process.exit(1);
}

testOpenRouter();
